{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_CLASSES = 3\n",
    "TRAIN_LANGUAGE_PREDICTOR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>version</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>url</th>\n",
       "      <th>review_id</th>\n",
       "      <th>category_final</th>\n",
       "      <th>sentiment_final</th>\n",
       "      <th>req_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52505.0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>246193109</td>\n",
       "      <td>Help is herr</td>\n",
       "      <td>2017-06-21 00:00:00</td>\n",
       "      <td>United States</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>53163.0</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         app_name    user_id     user_name                 date  \\\n",
       "52505.0  Facebook  246193109  Help is herr  2017-06-21 00:00:00   \n",
       "\n",
       "               country version  score                         topic  \\\n",
       "52505.0  United States      97      1  Notifications not showing up   \n",
       "\n",
       "                                                    review  \\\n",
       "52505.0  The notification badges are showing up on my i...   \n",
       "\n",
       "                                                       url  review_id  \\\n",
       "52505.0  https://itunes.apple.com/WebObjects/MZStore.wo...    53163.0   \n",
       "\n",
       "        category_final sentiment_final   req_final  \n",
       "52505.0    requirement         neutral  functional  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_raw = pd.read_excel(\"data/LData.xlsx\", index_col='Unnamed: 0')\n",
    "l_raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 3000 entries, 52505.0 to 45413.0\n",
      "Data columns (total 14 columns):\n",
      "app_name           3000 non-null object\n",
      "user_id            3000 non-null object\n",
      "user_name          2993 non-null object\n",
      "date               3000 non-null object\n",
      "country            3000 non-null object\n",
      "version            3000 non-null object\n",
      "score              3000 non-null int64\n",
      "topic              2994 non-null object\n",
      "review             2996 non-null object\n",
      "url                2850 non-null object\n",
      "review_id          2850 non-null float64\n",
      "category_final     3000 non-null object\n",
      "sentiment_final    2796 non-null object\n",
      "req_final          1081 non-null object\n",
      "dtypes: float64(1), int64(1), object(12)\n",
      "memory usage: 351.6+ KB\n"
     ]
    }
   ],
   "source": [
    "l_raw.info()\n",
    "la = l_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>version</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>url</th>\n",
       "      <th>review_id</th>\n",
       "      <th>category_final</th>\n",
       "      <th>sentiment_final</th>\n",
       "      <th>req_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>246193109</td>\n",
       "      <td>Help is herr</td>\n",
       "      <td>2017-06-21 00:00:00</td>\n",
       "      <td>United States</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>53163.0</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>43034279</td>\n",
       "      <td>javamdnss</td>\n",
       "      <td>2017-06-16 00:00:00</td>\n",
       "      <td>United States</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>Hate it!</td>\n",
       "      <td>Why do they make changes we don't need? Now th...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>53905.0</td>\n",
       "      <td>other</td>\n",
       "      <td>very negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>496978255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-27 00:00:00</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>Useless function n poor experience</td>\n",
       "      <td>Story is useless n annoying to user. \\nCan't s...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>47401.0</td>\n",
       "      <td>other</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>139595037</td>\n",
       "      <td>Gilbertiggy</td>\n",
       "      <td>2017-05-26 00:00:00</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>To many updates!</td>\n",
       "      <td>This app is always having an update for someth...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>42233.0</td>\n",
       "      <td>requirement</td>\n",
       "      <td>negative</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>180832062</td>\n",
       "      <td>Princess Lou 24</td>\n",
       "      <td>2017-06-01 00:00:00</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>Photo albums</td>\n",
       "      <td>Just spent an hour trying to upload photos and...</td>\n",
       "      <td>https://itunes.apple.com/WebObjects/MZStore.wo...</td>\n",
       "      <td>42066.0</td>\n",
       "      <td>requirement</td>\n",
       "      <td>negative</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_name    user_id        user_name                 date         country  \\\n",
       "0  Facebook  246193109     Help is herr  2017-06-21 00:00:00   United States   \n",
       "1  Facebook   43034279        javamdnss  2017-06-16 00:00:00   United States   \n",
       "2  Facebook  496978255              NaN  2017-05-27 00:00:00       Hong Kong   \n",
       "3  Facebook  139595037      Gilbertiggy  2017-05-26 00:00:00  United Kingdom   \n",
       "4  Facebook  180832062  Princess Lou 24  2017-06-01 00:00:00  United Kingdom   \n",
       "\n",
       "  version  score                               topic  \\\n",
       "0      97      1        Notifications not showing up   \n",
       "1      97      1                            Hate it!   \n",
       "2      94      1  Useless function n poor experience   \n",
       "3      94      1                    To many updates!   \n",
       "4      94      1                        Photo albums   \n",
       "\n",
       "                                              review  \\\n",
       "0  The notification badges are showing up on my i...   \n",
       "1  Why do they make changes we don't need? Now th...   \n",
       "2  Story is useless n annoying to user. \\nCan't s...   \n",
       "3  This app is always having an update for someth...   \n",
       "4  Just spent an hour trying to upload photos and...   \n",
       "\n",
       "                                                 url  review_id  \\\n",
       "0  https://itunes.apple.com/WebObjects/MZStore.wo...    53163.0   \n",
       "1  https://itunes.apple.com/WebObjects/MZStore.wo...    53905.0   \n",
       "2  https://itunes.apple.com/WebObjects/MZStore.wo...    47401.0   \n",
       "3  https://itunes.apple.com/WebObjects/MZStore.wo...    42233.0   \n",
       "4  https://itunes.apple.com/WebObjects/MZStore.wo...    42066.0   \n",
       "\n",
       "  category_final sentiment_final       req_final  \n",
       "0    requirement         neutral      functional  \n",
       "1          other   very negative             NaN  \n",
       "2          other        negative             NaN  \n",
       "3    requirement        negative      functional  \n",
       "4    requirement        negative  non-functional  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = la.reset_index(drop=True)\n",
    "la.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category_final</th>\n",
       "      <th>sentiment_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  score                         topic  \\\n",
       "0  United States      1  Notifications not showing up   \n",
       "\n",
       "                                              review category_final  \\\n",
       "0  The notification badges are showing up on my i...    requirement   \n",
       "\n",
       "  sentiment_final  \n",
       "0         neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = la.drop(['user_id', 'url', 'review_id', 'version', 'user_name', 'app_name', 'date', 'req_final'], axis=1)\n",
    "la.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rename label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  score                         topic  \\\n",
       "0  United States      1  Notifications not showing up   \n",
       "\n",
       "                                              review     category sentiment  \n",
       "0  The notification badges are showing up on my i...  requirement   neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = la.rename(columns = {\n",
    "    \"category_final\": \"category\",\n",
    "    \"sentiment_final\": \"sentiment\"\n",
    "}, errors=\"raise\")\n",
    "la.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2795 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      "country      2795 non-null object\n",
      "score        2795 non-null int64\n",
      "topic        2795 non-null object\n",
      "review       2795 non-null object\n",
      "category     2795 non-null object\n",
      "sentiment    2795 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 152.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# l = l[l['review'].notna()] # take the rows that are not NaN\n",
    "la = la.dropna() # remove any row with at least one value missing NaN\n",
    "la.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/2/library/string.html\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data, column):\n",
    "    \"\"\"\n",
    "    Uses string.punctuation list to remove unwarranted characeters\n",
    "    !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    \"\"\"\n",
    "    punctuation_table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [review.translate(punctuation_table) for review in data[column]]\n",
    "    return stripped\n",
    "\n",
    "def lowercase(data, column):\n",
    "    review_arr = data[column].to_list()\n",
    "    return [review.lower() for review in review_arr]\n",
    "\n",
    "def asciionly(data, column):\n",
    "    new_reviews = []\n",
    "    for review in data[column]:\n",
    "        review = re.sub('[^A-Za-z0-9\\s]', '', review)\n",
    "        new_reviews.append(review)\n",
    "    return new_reviews\n",
    "\n",
    "def new_line_to_space(data, column):\n",
    "    new_reviews = []\n",
    "    for review in data[column]:\n",
    "        nr = review.replace('\\n', ' ')\n",
    "        nr = nr.replace('\\t', '') # remove tab as well\n",
    "        new_reviews.append(nr)\n",
    "    return new_reviews\n",
    "\n",
    "def remove_single_characters(data, column):\n",
    "    new_reviews = []\n",
    "    for review in data[column]:\n",
    "        words = review.split(\" \")\n",
    "        new_words = []\n",
    "        for index, word in enumerate(words):\n",
    "            if (len(word) > 1):\n",
    "                new_words.append(word)\n",
    "        new_review = \" \".join(word for word in new_words)\n",
    "        new_reviews.append(new_review)\n",
    "    return new_reviews\n",
    "\n",
    "def remove_stopwords(data, column):\n",
    "    stop_words = set(stopwords.words('english')) - {'doing','having','because','into','against','over','under','why','no','not','only','same','just','should','now'}\n",
    "    new_reviews = []\n",
    "    for review in data[column]:\n",
    "        new_words = []\n",
    "        for word in review.split(\" \"):\n",
    "            if word not in stop_words:\n",
    "                new_words.append(word)\n",
    "        new_review = \" \".join(w for w in new_words)\n",
    "        new_reviews.append(new_review)  \n",
    "    return new_reviews\n",
    "\n",
    "def tokenize_words(data, column):\n",
    "    tokenized_reviews = []\n",
    "    for review in data[column]:\n",
    "        tokenized_reviews.append(word_tokenize(review))\n",
    "    return tokenized_reviews\n",
    "\n",
    "def stem(data, column):\n",
    "    porter = PorterStemmer()\n",
    "    new_reviews = []\n",
    "    for review_tokens in data[column]:\n",
    "        stemmed = [porter.stem(word) for word in review_tokens]\n",
    "        new_reviews.append(stemmed)\n",
    "    return new_reviews\n",
    "\n",
    "def lemmatize(data, column):\n",
    "    wnt = WordNetLemmatizer()\n",
    "    new_reviews = []\n",
    "    for review_tokens in data[column]:\n",
    "        lemmas = []   \n",
    "        for word in review_tokens:\n",
    "            lemma = wnt.lemmatize(word, pos='v')\n",
    "            lemmas.append(lemma)\n",
    "        new_reviews.append(lemmas)\n",
    "    return new_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  score                         topic  \\\n",
       "0  United States      1  Notifications not showing up   \n",
       "\n",
       "                                              review     category sentiment  \n",
       "0  The notification badges are showing up on my i...  requirement   neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Hate it!</td>\n",
       "      <td>Why do they make changes we don't need? Now th...</td>\n",
       "      <td>other</td>\n",
       "      <td>very negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>1</td>\n",
       "      <td>Useless function n poor experience</td>\n",
       "      <td>Story is useless n annoying to user. \\nCan't s...</td>\n",
       "      <td>other</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>To many updates!</td>\n",
       "      <td>This app is always having an update for someth...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>Photo albums</td>\n",
       "      <td>Just spent an hour trying to upload photos and...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  score                               topic  \\\n",
       "0   United States      1        Notifications not showing up   \n",
       "1   United States      1                            Hate it!   \n",
       "2       Hong Kong      1  Useless function n poor experience   \n",
       "3  United Kingdom      1                    To many updates!   \n",
       "4  United Kingdom      1                        Photo albums   \n",
       "\n",
       "                                              review     category  \\\n",
       "0  The notification badges are showing up on my i...  requirement   \n",
       "1  Why do they make changes we don't need? Now th...        other   \n",
       "2  Story is useless n annoying to user. \\nCan't s...        other   \n",
       "3  This app is always having an update for someth...  requirement   \n",
       "4  Just spent an hour trying to upload photos and...  requirement   \n",
       "\n",
       "       sentiment  \n",
       "0        neutral  \n",
       "1  very negative  \n",
       "2       negative  \n",
       "3       negative  \n",
       "4       negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_l = la.copy()\n",
    "norm_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, column):\n",
    "    data[column] = lowercase(data, column)\n",
    "    data[column] = remove_punctuation(data, column)\n",
    "    data[column] = asciionly(data, column)\n",
    "    data[column] = new_line_to_space(data, column)\n",
    "    data[column] = remove_single_characters(data, column)\n",
    "    data[column] = remove_stopwords(data, column)\n",
    "    data[column] = tokenize_words(data, column)\n",
    "#     data[column] = stem(data, column)\n",
    "    data[column] = lemmatize(data, column)\n",
    "    return data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>[notification, badge, show, iphone, plus, open...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  score                         topic  \\\n",
       "0  United States      1  Notifications not showing up   \n",
       "\n",
       "                                              review     category sentiment  \n",
       "0  [notification, badge, show, iphone, plus, open...  requirement   neutral  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize reviews\n",
    "norm_l['review'] = normalize(norm_l, 'review')\n",
    "norm_l.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cant', 'remove', 'reactions', 'interface', 'unusable', 'stupid']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display a review after normalizing\n",
    "r = norm_l['review'][321]\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_sentiment_labels(labels):\n",
    "    if SENTIMENT_CLASSES == 3:\n",
    "        pos = ['positive', 'positve', 'postive', 'very positive']\n",
    "        neg = ['negative', 'very negative']\n",
    "        neu = ['neutral']\n",
    "        \n",
    "    elif SENTIMENT_CLASSES == 5:\n",
    "        pos = ['positive', 'positve', 'postive']\n",
    "        neg = ['negative']\n",
    "        neu = ['neutral']\n",
    "    \n",
    "    new_labels = []\n",
    "\n",
    "    for label in labels:\n",
    "        label = label.lower()\n",
    "        if label in pos:\n",
    "            label = \"positive\"\n",
    "        elif label in neg:\n",
    "            label = \"negative\"\n",
    "        elif label in neu:\n",
    "            label = \"neutral\"\n",
    "        new_labels.append(label)\n",
    "    return pd.Series(new_labels)\n",
    "\n",
    "def collapse_category_labels(labels):\n",
    "    new_labels = []\n",
    "    req = ['requirement', 'Requirement']\n",
    "    oth = ['Other', 'other']\n",
    "    bug = ['bug report', 'Bug report']\n",
    "    for label in labels:\n",
    "        label = label.lower()\n",
    "        if label in req:\n",
    "            new_labels.append('requirement')\n",
    "        elif label in oth:\n",
    "            new_labels.append('other')\n",
    "        elif label in bug:\n",
    "            new_labels.append('bug report')\n",
    "    return pd.Series(new_labels)\n",
    "\n",
    "def stringify_reviews(reviews):\n",
    "    new_reviews = []\n",
    "    for review in reviews:\n",
    "        new_reviews.append(str(review))\n",
    "    return new_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def train_clfs(reviews, labels, mf=5000):\n",
    "    \"\"\"\n",
    "    Encode target labels with value between 0 and n_classes-1.\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    \n",
    "    \"\"\"\n",
    "    Split training and test data (70/30)\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        reviews,\n",
    "        encoded_labels,\n",
    "        random_state=8,\n",
    "        train_size=0.7\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    TF-IDF\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_vectorizer.fit(reviews) # on the entire vocabulary\n",
    "    \n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    \"\"\"\n",
    "    Models\n",
    "    \"\"\"\n",
    "    nb = naive_bayes.MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "    nb_y_preds = nb.predict(X_test_tfidf)\n",
    "    print_performance(\"multinomial naive bayes\",\n",
    "                     y_test, nb_y_preds)\n",
    "    \n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', gamma='auto').fit(X_train_tfidf, y_train)\n",
    "    SVM_y_preds = SVM.predict(X_test_tfidf)\n",
    "    print_performance(\"linear svm\", y_test, SVM_y_preds)\n",
    "\n",
    "    count_vectorizer = CountVectorizer(min_df=25, ngram_range=(1,2))\n",
    "    count_vectorizer.fit(X_train)\n",
    "    X_train_vect = count_vectorizer.transform(X_train)\n",
    "    X_test_vect = count_vectorizer.transform(X_test)\n",
    "    \n",
    "    lr = LogisticRegression(solver='liblinear', multi_class='auto').fit(X_train_vect, y_train)\n",
    "    lr_y_preds = lr.predict(X_test_vect)\n",
    "    print_performance(\"logistic regression\", y_test, lr_y_preds)\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=50).fit(X_train_tfidf, y_train)\n",
    "    X_vect_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    rf_y_preds = rf.predict(X_vect_test_tfidf)\n",
    "    print_performance(\"random forest\", y_test, rf_y_preds)\n",
    "    \n",
    "    sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                             alpha=1e-3, random_state=42,\n",
    "                             max_iter=5, tol=None).fit(X_train_tfidf, y_train)\n",
    "    sgd_y_preds = sgd.predict(X_vect_test_tfidf)\n",
    "    print_performance(\"linear svm, sgd training\", y_test, sgd_y_preds)\n",
    "    \n",
    "def print_performance(title, test, predicted):\n",
    "    print(f'/\\/\\/\\/\\/ {title}')\n",
    "    print(\"Recall\\t\\t\",recall_score(test, predicted, average=\"weighted\")*100)\n",
    "    print()\n",
    "    print(\"Precision\\t\", precision_score(test, predicted, average='weighted')*100)\n",
    "    print()\n",
    "    print(\"F1\\t\\t\", f1_score(test, predicted, average='weighted')*100, \"\\n\")\n",
    "    \n",
    "    \n",
    "def train_sgd(reviews, labels):\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(min_df=25, ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                             alpha=1e-3, random_state=42,\n",
    "                             max_iter=8, tol=None)),\n",
    "    ])\n",
    "    encoder = LabelEncoder()\n",
    "    e_labels = encoder.fit_transform(labels)\n",
    "    print(f\"SGD classifier trained with labels: {labels.unique()}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(reviews, e_labels,\n",
    "                                                                        random_state=42, train_size=0.7)\n",
    "    \n",
    "    text_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = text_clf.predict(X_test)\n",
    "#     print(np.mean(y_pred == y_test))\n",
    "    print_performance(\"sgd\", y_test, y_pred)\n",
    "    return text_clf, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(reviews, X_train):\n",
    "    tfidf_vectorizer.fit(reviews)\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    return X_train_tfidf\n",
    "    \n",
    "def get_count_vect(X_train, X_test):\n",
    "    count_vectorizer.fit(X_train)\n",
    "    X_train_vect = count_vectorizer.transform(X_train)\n",
    "    return X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, list_of_features):\n",
    "    enriched_reviews = []\n",
    "    for index, row in df.iterrows():\n",
    "        features = []\n",
    "        for f in list_of_features:\n",
    "            features.append(row[f])\n",
    "        enriched_review = \"\"\n",
    "        for feature in features:\n",
    "            enriched_review += str(feature) + \" \"\n",
    "        enriched_review += row['review']\n",
    "        enriched_reviews.append(enriched_review)\n",
    "    return enriched_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = collapse_sentiment_labels(norm_l['sentiment'])\n",
    "reviews = stringify_reviews(norm_l['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-class classification\n",
    "labels.unique()\n",
    "# norm_l['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Notifications not showing up</td>\n",
       "      <td>The notification badges are showing up on my i...</td>\n",
       "      <td>requirement</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  score                         topic  \\\n",
       "0  United States      1  Notifications not showing up   \n",
       "\n",
       "                                              review     category sentiment  \n",
       "0  The notification badges are showing up on my i...  requirement   neutral  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf = la.copy()\n",
    "lf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf['review'] = add_features(lf, ['topic', 'score'])\n",
    "lf['review'] = normalize(lf, 'review')\n",
    "lf['review'] = stringify_reviews(lf['review'])\n",
    "\n",
    "f_reviews = lf['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD classifier trained with labels: ['neutral' 'negative' 'positive']\n",
      "/\\/\\/\\/\\/ sgd\n",
      "Recall\t\t 64.60071513706794\n",
      "\n",
      "Precision\t 63.884366691851525\n",
      "\n",
      "F1\t\t 64.1435471227908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_clf, sen_enc = train_sgd(f_reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\\/\\/\\/\\/ multinomial naive bayes\n",
      "Recall\t\t 67.69964243146603\n",
      "\n",
      "Precision\t 68.25623676241854\n",
      "\n",
      "F1\t\t 65.72330950209971 \n",
      "\n",
      "/\\/\\/\\/\\/ linear svm\n",
      "Recall\t\t 68.41477949940405\n",
      "\n",
      "Precision\t 68.61888714469484\n",
      "\n",
      "F1\t\t 68.50928834388377 \n",
      "\n",
      "/\\/\\/\\/\\/ logistic regression\n",
      "Recall\t\t 65.43504171632897\n",
      "\n",
      "Precision\t 64.9754778090274\n",
      "\n",
      "F1\t\t 65.14375692332341 \n",
      "\n",
      "/\\/\\/\\/\\/ random forest\n",
      "Recall\t\t 67.81883194278903\n",
      "\n",
      "Precision\t 67.1657614431597\n",
      "\n",
      "F1\t\t 67.2525943980427 \n",
      "\n",
      "/\\/\\/\\/\\/ linear svm, sgd training\n",
      "Recall\t\t 70.32181168057211\n",
      "\n",
      "Precision\t 69.4633145303935\n",
      "\n",
      "F1\t\t 69.41741519577468 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_clfs(f_reviews, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAM TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589996868312542"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(sen_clf, parameters, cv=5, n_jobs=1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "e_labels = encoder.fit_transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(f_reviews, e_labels,\n",
    "                                                                    random_state=42, train_size=0.7)\n",
    "\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(sen_clf, f_reviews, labels, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463, 139,  67],\n",
       "       [202, 276, 120],\n",
       "       [ 70,  69, 550]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sen_clf, X_train, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred, labels=[0, 1, 2]) # neg, neut, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The notification badges are showing up on my iPhone 6 Plus but when I open app there not there. This has happened since last update. \\nAlso quit interrupting videos with stupid ads. Annoying.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la['review'][0] # original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['notification', 'badge', 'show', 'iphone', 'plus', 'open', 'app', 'not', 'happen', 'since', 'last', 'update', 'also', 'quit', 'interrupt', 'videos', 'stupid', 'ads', 'annoy']\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(norm_l['review'][0]) # normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['notifications', 'not', 'show', 'notification', 'badge', 'show', 'iphone', 'plus', 'open', 'app', 'not', 'happen', 'since', 'last', 'update', 'also', 'quit', 'interrupt', 'videos', 'stupid', 'ads', 'annoy']\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(lf['review'][0]) # normalized, with additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDENTIFY LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of text snippplets: 63156\n",
      "________________________________\n",
      "Greek                    6681\n",
      "French                   6466\n",
      "German                   6395\n",
      "Italian                  6383\n",
      "Portuguese               6147\n",
      "Spanish                  6016\n",
      "Finnish                  5597\n",
      "Swedish                  4940\n",
      "Danish                   4914\n",
      "Dutch                    4826\n",
      "English                  4791\n",
      "Counting Chars:\n",
      "γ ù e ι û έ ï δ à η ã ξ μ ν g u j d o å k ë ί ø τ æ h î ΐ ô w v è ö ώ ο º σ â θ κ ê x l π φ ή ά ò á ì p ó ΰ ε é n ψ ú β ό z í ñ y λ t ρ ς i ß ç υ ω b q c ύ ϊ χ õ m ζ r s α a f ª ü ϋ ä k\tPercentage of correctly predicted language\n",
      "__________________________________________________\n",
      "1\t97.878%\n",
      "2\t97.934%\n",
      "3\t98.456%\n",
      "4\t98.623%\n",
      "5\t98.623%\n",
      "6\t98.63%\n",
      "7\t98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of text snippplets: 63156\n",
      "________________________________\n",
      "Greek                    6681\n",
      "French                   6466\n",
      "German                   6395\n",
      "Italian                  6383\n",
      "Portuguese               6147\n",
      "Spanish                  6016\n",
      "Finnish                  5597\n",
      "Swedish                  4940\n",
      "Danish                   4914\n",
      "Dutch                    4826\n",
      "English                  4791\n",
      "Counting Chars:\n",
      "γ ù e ι û έ ï δ à η ã ξ μ ν g u j d o å k ë ί ø τ æ h î ΐ ô "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-34-c20a84ccdd55>\", line 2, in <module>\n",
      "    from scripts.lang_predict import predict_lang\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 120, in <module>\n",
      "    ratio_correct = test_knn(clf, X, Y)\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 112, in test_knn\n",
      "    predictions = clf.predict(X)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\", line 173, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 663, in kneighbors\n",
      "    for s in gen_even_slices(X.shape[0], n_jobs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 490, in _tree_query_parallel_helper\n",
      "    return tree.query(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-34-c20a84ccdd55>\", line 8, in <module>\n",
      "    import scripts.lang_predict as lp\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 75, in <module>\n",
      "    features, df = calc_charratios(df)\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 72, in calc_charratios\n",
      "    df[c] = [r.count(c) for r in df['ltext']] / df['len']\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\", line 1048, in wrapper\n",
      "    result = na_op(lvalues, rvalues)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\", line 968, in na_op\n",
      "    result = expressions.evaluate(op, str_rep, x, y, **eval_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/computation/expressions.py\", line 221, in evaluate\n",
      "    return _evaluate(op, op_str, a, b, **eval_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/computation/expressions.py\", line 70, in _evaluate_standard\n",
      "    return op(a, b)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/roperator.py\", line 25, in rtruediv\n",
      "    return right / left\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 396, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 362, in normpath\n",
      "    if comp in (empty, dot):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-34-c20a84ccdd55>\", line 2, in <module>\n",
      "    from scripts.lang_predict import predict_lang\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 120, in <module>\n",
      "    ratio_correct = test_knn(clf, X, Y)\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 112, in test_knn\n",
      "    predictions = clf.predict(X)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\", line 173, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 663, in kneighbors\n",
      "    for s in gen_even_slices(X.shape[0], n_jobs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 490, in _tree_query_parallel_helper\n",
      "    return tree.query(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-34-c20a84ccdd55>\", line 8, in <module>\n",
      "    import scripts.lang_predict as lp\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 75, in <module>\n",
      "    features, df = calc_charratios(df)\n",
      "  File \"/Users/gohost/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\", line 72, in calc_charratios\n",
      "    df[c] = [r.count(c) for r in df['ltext']] / df['len']\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\", line 1048, in wrapper\n",
      "    result = na_op(lvalues, rvalues)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/__init__.py\", line 968, in na_op\n",
      "    result = expressions.evaluate(op, str_rep, x, y, **eval_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/computation/expressions.py\", line 221, in evaluate\n",
      "    return _evaluate(op, op_str, a, b, **eval_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/computation/expressions.py\", line 70, in _evaluate_standard\n",
      "    return op(a, b)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/ops/roperator.py\", line 25, in rtruediv\n",
      "    return right / left\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2043, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: can only concatenate str (not \"list\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 687, in getsourcefile\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c20a84ccdd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_predict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mratio_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_correct\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/anomales/jupyter-notebooks/user-reviews/scripts/lang_predict.py\u001b[0m in \u001b[0;36mtest_knn\u001b[0;34m(clf, X, Y)\u001b[0m\n\u001b[1;32m    111\u001b[0m     '''\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mratio_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    662\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3341\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3342\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3345\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2043\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1385\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1288\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from scripts.lang_predict import predict_lang\n",
    "    \n",
    "    lang_clf_file = open('pkl/lang_pred.pkl', 'rb')\n",
    "    lang_clf = pickle.load(lang_clf_file)\n",
    "    print(\"Loaded from cache\")\n",
    "except:\n",
    "    import scripts.lang_predict as lp\n",
    "    \n",
    "    lp.predict_lang(\"Wow, what an application, really nothing bad to say about this what so ever\")\n",
    "    lang_clf_file = open('pkl/lang_pred.pkl', 'wb')\n",
    "    pickle.dump(lp.clf, lang_clf_file)\n",
    "    print(\"Cached classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.predict_lang(\"Jeg gikk en tur i skogen i går og det var kjempekult, må gjentas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.predict_lang(\"Once upon a time there was a really small thing that moved on to the bigger thing, over there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.predict_lang(\"Ik ben makelaar in koffi, en woon op de Lauriergracht No 37. Het is mijn gewoonte niet, romans te schrijven, of zulke dingen, en het heeft dan ook lang geduurd, voor ik er toe overging een paar riem papier extra te bestellen, en het werk aan te vangen, dat gij, lieve lezer, zoâven in de hand hebt genomen, en dat ge lezen moet als ge makelaar in koffie zijt, of als ge wat anders zijt. Niet alleen dat ik nooit iets schreef wat naar een roman geleek, maar ik houd er zelfs niet van, iets dergelijks te lezen, omdat ik een man van zaken ben.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfe = la.copy()\n",
    "lfe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LANGUAGE_PREDICTOR == True:\n",
    "    lfe = drop_non_english(lfe)\n",
    "\n",
    "    lfe['review'] = add_features(lfe, ['topic', 'score'])\n",
    "    lfe_reviews = normalize(lfe, 'review')\n",
    "    lfe_reviews = stringify_reviews(lfe_reviews)\n",
    "\n",
    "    lfe_labels = collapse_sentiment_labels(lfe['sentiment'])\n",
    "    lfe_labels.unique()\n",
    "\n",
    "    train_clfs(lfe_reviews, lfe_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORY CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_clf, cat_enc = train_sgd(\n",
    "    stringify_reviews(lf['review']),\n",
    "    collapse_category_labels(lf['category'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_clf, sen_enc = train_sgd(\n",
    "    stringify_reviews(lf['review']),\n",
    "    collapse_sentiment_labels(lf['sentiment'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFYING GOOGLE PLAY REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('data/gplay_reviews/com.reddit.frontpage.csv', index_col=\"Timestamp\", parse_dates=True)\n",
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to speed up computation, select 10000 reviews\n",
    "reddit_sample = reddit.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_reviews(df):\n",
    "    for index, row in df.iterrows():\n",
    "        r = row['Review']\n",
    "        if type(r) != str:\n",
    "            df.drop(index, inplace=True)\n",
    "    return df\n",
    "\n",
    "def remove_short_reviews(data):\n",
    "    return data[data['Review'].str.len() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_sample = remove_short_reviews(reddit_sample)\n",
    "reddit_sample = drop_empty_reviews(reddit_sample)\n",
    "reddit_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of 10,000 reviews\n",
    "# only 33% were more than 50 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_reviews = normalize(reddit_sample, 'Review')\n",
    "reddit_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_cat_y_pred = cat_clf.predict(stringify_reviews(reddit_reviews))\n",
    "reddit_sen_y_pred = sen_clf.predict(stringify_reviews(reddit_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "reddit_data = {\n",
    "    'review': reddit_reviews,\n",
    "    'category': cat_enc.inverse_transform(reddit_cat_y_pred),\n",
    "    'sentiment': sen_enc.inverse_transform(reddit_sen_y_pred)\n",
    "}\n",
    "te = pd.DataFrame(reddit_data)\n",
    "te = te.reset_index(drop=True)\n",
    "te.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_path = \"data/reviews_with_truthset/reviews_with_truthset.db\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "conn.text_factory = lambda b: b.decode(errors = 'ignore')\n",
    "\n",
    "l2 = pd.read_sql_query(\"SELECT * FROM labeledreviews\", conn, index_col='id')\n",
    "l2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2['review_text'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2['sentimentScore'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE SENTIMENT LABELS OF NEW DATA TO FIT THE CURRENT ENCODER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURRENT SENTIMENT CLASSES MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Negative: 0\n",
    "- Neutral: 1\n",
    "- Positive: 2\n",
    "- Very negative: 3\n",
    "- Very positive: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_enc.transform(sen_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2.sentimentScore.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the above cell, the labels for sentiment in the new training data are different than what we currently have. It is a more logical mapping, with negative values for negative sentiment, vice versa, but we'll make it fit our current setup nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 5-class\n",
    "la2 = l2.copy()\n",
    "nsl = [] # new_sentiment_labels\n",
    "\n",
    "if SENTIMENT_CLASSES == 5:\n",
    "    for index, row in l2.iterrows():\n",
    "        if row.sentimentScore == -2:\n",
    "            nsl.append(3)\n",
    "        elif row.sentimentScore == -1:\n",
    "            nsl.append(0)\n",
    "        elif row.sentimentScore == 0:\n",
    "            nsl.append(1)\n",
    "        elif row.sentimentScore == 1:\n",
    "            nsl.append(2)\n",
    "        elif row.sentimentScore == 2:\n",
    "            nsl.append(4)\n",
    "elif SENTIMENT_CLASSES == 3:\n",
    "    for index, row in l2.iterrows():\n",
    "        if row.sentimentScore == -2:\n",
    "            nsl.append(0)\n",
    "        elif row.sentimentScore == -1:\n",
    "            nsl.append(0)\n",
    "        elif row.sentimentScore == 0:\n",
    "            nsl.append(1)\n",
    "        elif row.sentimentScore == 1:\n",
    "            nsl.append(2)\n",
    "        elif row.sentimentScore == 2:\n",
    "            nsl.append(2)\n",
    "\n",
    "la2['sentimentScore'] = nsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2 = la2[['country', 'score', 'topic', 'review_text', 'sentimentScore']]\n",
    "la2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2 = la2.rename(columns = {\n",
    "    \"review_text\": \"review\",\n",
    "    \"sentimentScore\": \"sentiment\"\n",
    "}, errors=\"raise\")\n",
    "la2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2.sentiment = sen_enc.inverse_transform(la2.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN WITH COMBINED LABELS AND REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print length of la (labeled data 1 - req. eng.) and la2 (labeled data 2 - culture study)\n",
    "# also print length of la + la2 i.e. combined training data\n",
    "print(len(la.review),\n",
    "     len(la2.review),\n",
    "      (len(la.review) + len(la2.review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac = pd.concat([la, la2])\n",
    "lac = lac.drop(['category'], axis=1)\n",
    "lac.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac['review'] = add_features(lac, ['topic', 'score'])\n",
    "lac['review'] = normalize(lac, 'review')\n",
    "lac['review'] = stringify_reviews(lac['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_clf, sen_enc = train_sgd(\n",
    "    stringify_reviews(lac['review']),\n",
    "    collapse_sentiment_labels(lac['sentiment'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clfs(stringify_reviews(lac['review']),\n",
    "          collapse_sentiment_labels(lac['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def piec(s, l):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(s, labels=l, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.axis('equal')\n",
    "    plt.figure(figsize=(20,10)) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPT: LABEL DISTRIBUTION IN TRAINING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REQUIREMENTS ENGINEERING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = la['sentiment']\n",
    "labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "sizes = [\n",
    "    len(sen[la.sentiment == 'very negative']),\n",
    "    len(sen[la.sentiment == 'negative']),\n",
    "    len(sen[la.sentiment == 'neutral']),\n",
    "    len(sen[la.sentiment == 'positive']),\n",
    "    len(sen[la.sentiment == 'very positive'])\n",
    "]\n",
    "piec(sizes, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORY CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = collapse_category_labels(la['category'])\n",
    "categories.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories[categories == 'requirement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['requirement', 'other', 'bug report']\n",
    "sizes = [\n",
    "    len(categories[categories == 'requirement']),\n",
    "    len(categories[categories == 'other']),\n",
    "    len(categories[categories == 'bug report'])\n",
    "]\n",
    "piec(sizes, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CULTURE STUDY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = l2['sentimentScore']\n",
    "labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "sizes = [\n",
    "    len(sen[l2.sentimentScore == -2]),\n",
    "    len(sen[l2.sentimentScore == -1]),\n",
    "    len(sen[l2.sentimentScore == 0]),\n",
    "    len(sen[l2.sentimentScore == 1]),\n",
    "    len(sen[l2.sentimentScore == 2]),\n",
    "]\n",
    "piec(sizes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bug_reports = la[la.category == 'bug report']\n",
    "labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "sizes = []\n",
    "for l in labels:\n",
    "    sizes.append(len(bug_reports[bug_reports.sentiment == l]))\n",
    "piec(sizes, labels)\n",
    "# sentiment distribution in \"bug report\" reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = la[la.category == 'requirement']\n",
    "labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "sizes = []\n",
    "for l in labels:\n",
    "    sizes.append(len(requirements[requirements.sentiment == l]))\n",
    "\n",
    "piec(sizes, labels)\n",
    "# sentiment distribution in \"requirement\" reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
